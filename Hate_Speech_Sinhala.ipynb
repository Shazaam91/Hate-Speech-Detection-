{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7JzF+a2pYaUyPBxSUyHCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shazaam91/Hate-Speech-Detection-/blob/BiLSTM/Hate_Speech_Sinhala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import gzip\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "id": "AvJyJb6Q1IMJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTt_BBHm1NYX",
        "outputId": "ccad07d0-d1a2-4a32-9213-ef81fa54b582"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install fasttext\n",
        "! pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iw7ywdk1ULe",
        "outputId": "ae94b0ae-b22d-4bab-9049-4b557162f2c6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.13.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.vec.gz\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6jtXsH1aRQ",
        "outputId": "fc9fe7b1-5172-423c-8280-d39930493937"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-18 19:42:27--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.74.45, 13.227.74.118, 13.227.74.9, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.74.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 481477801 (459M) [binary/octet-stream]\n",
            "Saving to: ‘cc.si.300.vec.gz.7’\n",
            "\n",
            "cc.si.300.vec.gz.7  100%[===================>] 459.17M  38.5MB/s    in 12s     \n",
            "\n",
            "2024-08-18 19:42:39 (39.1 MB/s) - ‘cc.si.300.vec.gz.7’ saved [481477801/481477801]\n",
            "\n",
            "--2024-08-18 19:42:39--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.si.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.74.45, 13.227.74.118, 13.227.74.9, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.74.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3181346570 (3.0G) [application/octet-stream]\n",
            "Saving to: ‘cc.si.300.bin.gz.6’\n",
            "\n",
            "cc.si.300.bin.gz.6  100%[===================>]   2.96G  30.5MB/s    in 89s     \n",
            "\n",
            "2024-08-18 19:44:08 (34.3 MB/s) - ‘cc.si.300.bin.gz.6’ saved [3181346570/3181346570]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "# Path to the gzip file\n",
        "gzip_file_path = '/content/cc.si.300.bin.gz'\n",
        "# Path where the extracted file will be saved\n",
        "extracted_file_path = '/content/cc.si.300.bin'\n",
        "\n",
        "# Remove the file if it already exists to avoid overwrite prompt\n",
        "if os.path.exists(extracted_file_path):\n",
        "    os.remove(extracted_file_path)\n",
        "\n",
        "# Extract the gzip file\n",
        "with gzip.open(gzip_file_path, 'rb') as f_in:\n",
        "    with open(extracted_file_path, 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n"
      ],
      "metadata": {
        "id": "DD0qENU612aR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!sudo python setup.py install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHzRcIA2Awc",
        "outputId": "07ac9a30-87a2-4a39-ab8d-7f9d98bacac3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fastText' already exists and is not an empty directory.\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "ft = fasttext.load_model('/content/cc.si.300.bin')\n",
        "ft.get_dimension()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rkg8_pf2vfy",
        "outputId": "469204ab-1d82-4602-dcf5-d2883509b96d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext.util.reduce_model(ft, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_1vKRt53Aqm",
        "outputId": "fbe5408a-4dda-417d-9e68-cb7a98d90b0e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fasttext.FastText._FastText at 0x7b38eff9e770>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset\n",
        "dataset = []\n",
        "error_count = 0  # To count errors"
      ],
      "metadata": {
        "id": "pMSHRUjb3J1s"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"/content/drive/MyDrive/sinhala-hate-speech-dataset.csv\") as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    header = reader.fieldnames\n",
        "    print(\"Header Row:\", header)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqiZahcz3WX7",
        "outputId": "2c9b9f7d-7c92-42a7-cef6-7961b6a19139"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header Row: ['id', 'comment', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset using the correct column names\n",
        "dataset = []\n",
        "error_count = 0  # To count errors\n",
        "\n",
        "with open(\"/content/drive/MyDrive/sinhala-hate-speech-dataset.csv\") as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for i, row in enumerate(reader):\n",
        "        post = row['comment']  # Correct column name for the post\n",
        "        label = row['label']  # Correct column name for the label\n",
        "\n",
        "        # Skip rows with empty post or label\n",
        "        if not post or not label:\n",
        "            print(f\"Skipping row {i}: missing post or label\")\n",
        "            continue\n",
        "\n",
        "        item = [post]\n",
        "\n",
        "        if label == '0':\n",
        "            item.append(0)\n",
        "        elif label == '1':\n",
        "            item.append(1)\n",
        "        else:\n",
        "            print(f\"ERROR at row {i}: Unexpected label {label}\")\n",
        "            error_count += 1\n",
        "            continue\n",
        "\n",
        "        dataset.append(item)"
      ],
      "metadata": {
        "id": "8sLQGu4x3aAj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final counts\n",
        "print(f\"Total rows processed: {i + 1}\")\n",
        "print(f\"Total valid entries: {len(dataset)}\")\n",
        "print(f\"Total errors: {error_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbsI-vL3gX0",
        "outputId": "c7dfaee9-bc65-4542-d8fa-e16d98c73a4d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows processed: 6345\n",
            "Total valid entries: 6345\n",
            "Total errors: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the lengths of posts and labels\n",
        "posts = [item[0] for item in dataset]\n",
        "labels = [item[1] for item in dataset]\n",
        "\n",
        "print(f\"Length of posts: {len(posts)}\")\n",
        "print(f\"Length of labels: {len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvTj2FdF3j2x",
        "outputId": "aed71a19-a694-44fe-855e-8bc4baada452"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of posts: 6345\n",
            "Length of labels: 6345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate posts and labels\n",
        "posts = [item[0] for item in dataset]\n",
        "labels = [item[1] for item in dataset]\n",
        "\n",
        "# Check the lengths to ensure they match\n",
        "print(f\"Length of posts: {len(posts)}\")\n",
        "print(f\"Length of labels: {len(labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQUCnRze3mb2",
        "outputId": "a0093cd6-bf22-44e0-fc61-041f5e0f5da8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of posts: 6345\n",
            "Length of labels: 6345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize posts before resampling\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(posts)\n",
        "sequences = tokenizer.texts_to_sequences(posts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=120)\n",
        "\n",
        "# Convert labels to a NumPy array for SMOTE\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "sm = SMOTE(random_state=42)\n",
        "padded_sequences, labels = sm.fit_resample(padded_sequences, labels)"
      ],
      "metadata": {
        "id": "nJXYXvyP3vds"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "padded_sequences_train, padded_sequences_test, labels_train, labels_test = train_test_split(\n",
        "    np.asarray(padded_sequences),\n",
        "    np.asarray(labels),\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "IGW00XcH3z3h"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusing the tokenizer from the previous step, so no need to redefine it\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Ensure that vocab_size includes all unique words plus one for padding\n",
        "\n",
        "embedding_dim = 100\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "oov_tok = \"\"\n",
        "\n",
        "# The padded_sequences_train and padded_sequences_test are already prepared, so no need to re-tokenize\n",
        "padded = padded_sequences_train\n",
        "testing_padded = padded_sequences_test\n"
      ],
      "metadata": {
        "id": "FskdtqjN33-W"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define word_index to avoid NameError\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Create embeddings_matrix\n",
        "embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i < vocab_size:  # Ensure the index is within the vocabulary size\n",
        "        try:\n",
        "            embedding_vector = ft.get_word_vector(word)\n",
        "            if embedding_vector is not None:\n",
        "                embeddings_matrix[i] = embedding_vector\n",
        "        except KeyError:\n",
        "            # Handle the case where the word is not found in FastText model\n",
        "            continue\n",
        "\n"
      ],
      "metadata": {
        "id": "J-eXUdAE37kx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # Embedding layer with pre-trained embeddings\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,  # Use vocab_size without +1\n",
        "        output_dim=embedding_dim,\n",
        "        input_length=max_length,\n",
        "        weights=[embeddings_matrix],\n",
        "        trainable=False\n",
        "    ),\n",
        "    # Bidirectional LSTM layer\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, dropout=0.5)),\n",
        "    # Dense layer with ReLU activation and L2 regularization\n",
        "    tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    # Output layer for binary classification\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SldZP0-S4AT3",
        "outputId": "42e87ac7-a864-4971-8947-f934f1fd218a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "WWwZUoxF4zmK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((None, max_length))  # Adjust input shape if needed\n"
      ],
      "metadata": {
        "id": "zKR5NH9s5WQc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "oZrNgPb65Y3I",
        "outputId": "dc46de9c-c702-4166-9eae-ada3c319223c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m1,881,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m34,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m1,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m25\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,881,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,916,733\u001b[0m (7.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,916,733</span> (7.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,633\u001b[0m (139.19 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,633</span> (139.19 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,881,100\u001b[0m (7.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,881,100</span> (7.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "SiVApupF5anx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define early stopping and model checkpoint callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "num_epochs = 100\n",
        "history = model.fit(\n",
        "    padded_sequences_train,  # Training data\n",
        "    labels_train,            # Training labels\n",
        "    epochs=num_epochs,       # Number of epochs\n",
        "    batch_size=32,           # Batch size\n",
        "    validation_split=0.1,   # Fraction of training data to use as validation data\n",
        "    callbacks=[early_stopping, checkpoint]  # Callbacks to monitor training\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2L_T7ZG7Lth",
        "outputId": "f6932cde-a4fc-4693-f80c-4de251a80926"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 103ms/step - accuracy: 0.6605 - loss: 0.6815 - val_accuracy: 0.7797 - val_loss: 0.4838\n",
            "Epoch 2/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - accuracy: 0.7743 - loss: 0.4896 - val_accuracy: 0.7846 - val_loss: 0.5078\n",
            "Epoch 3/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 100ms/step - accuracy: 0.7715 - loss: 0.4804 - val_accuracy: 0.8087 - val_loss: 0.4383\n",
            "Epoch 4/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.7875 - loss: 0.4687 - val_accuracy: 0.8119 - val_loss: 0.4149\n",
            "Epoch 5/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 98ms/step - accuracy: 0.7990 - loss: 0.4407 - val_accuracy: 0.8039 - val_loss: 0.4378\n",
            "Epoch 6/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 99ms/step - accuracy: 0.8017 - loss: 0.4296 - val_accuracy: 0.8183 - val_loss: 0.4227\n",
            "Epoch 7/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 100ms/step - accuracy: 0.7999 - loss: 0.4396 - val_accuracy: 0.8264 - val_loss: 0.4277\n",
            "Epoch 8/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.8206 - loss: 0.4021 - val_accuracy: 0.8087 - val_loss: 0.4185\n",
            "Epoch 9/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.8095 - loss: 0.4089 - val_accuracy: 0.8071 - val_loss: 0.4073\n",
            "Epoch 10/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.8103 - loss: 0.4188 - val_accuracy: 0.7878 - val_loss: 0.4782\n",
            "Epoch 11/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.7857 - loss: 0.4714 - val_accuracy: 0.7894 - val_loss: 0.4383\n",
            "Epoch 12/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 102ms/step - accuracy: 0.7886 - loss: 0.4543 - val_accuracy: 0.8006 - val_loss: 0.4468\n",
            "Epoch 13/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 108ms/step - accuracy: 0.8024 - loss: 0.4341 - val_accuracy: 0.8135 - val_loss: 0.4219\n",
            "Epoch 14/100\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - accuracy: 0.8273 - loss: 0.4006 - val_accuracy: 0.8039 - val_loss: 0.4260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n"
      ],
      "metadata": {
        "id": "He5SoMwG7eg7"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(testing_padded, labels_test, batch_size=32)\n",
        "print(f\"Test Loss: {result[0]}\")\n",
        "print(f\"Test Accuracy: {result[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFQQacmtsBe_",
        "outputId": "43c82786-3501-40fc-b154-e6ac7cfec0a9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8785 - loss: 0.3130 - precision_3: 0.9006 - recall_3: 0.8766\n",
            "Test Loss: 0.330152690410614\n",
            "Test Accuracy: 0.8596237301826477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB7GfGQTwgpj",
        "outputId": "8191aec4-508e-4135-ef92-ec186458ef85"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Embedding layer with pretrained embeddings\n",
        "    model.add(tf.keras.layers.Embedding(vocab_size+1,\n",
        "                                        embedding_dim,\n",
        "                                        input_length=max_length,\n",
        "                                        weights=[embeddings_matrix],\n",
        "                                        trainable=False))\n",
        "\n",
        "    # Bidirectional LSTM layer\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
        "        units=hp.Int('units', min_value=16, max_value=128, step=16),\n",
        "        dropout=hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
        "    )))\n",
        "\n",
        "    # Dense layer\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        units=hp.Int('dense_units', min_value=16, max_value=128, step=16),\n",
        "        activation='relu',\n",
        "        kernel_regularizer=l2(0.01)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eGCcmyTqz5ps"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = embeddings_matrix.shape[0] - 1\n"
      ],
      "metadata": {
        "id": "d8lIqjsU0cxc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                              output_dim=embedding_dim,\n",
        "                              input_length=max_length,\n",
        "                              weights=[embeddings_matrix],\n",
        "                              trainable=False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, dropout=0.5)),\n",
        "    tf.keras.layers.Dense(24, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "q4TTWdJW0eZr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_random_search= kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='hate_speech_detection'\n",
        ")\n",
        "\n",
        "tuner_random_search.search(padded, labels_train,\n",
        "             epochs=10,\n",
        "             validation_data=(testing_padded, labels_test),\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrJev0f0z_MX",
        "outputId": "08c8ded4-4a8f-42af-cf0d-139aa447d31f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/hate_speech_detection/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner_random_search.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfWZJQck0Dxv",
        "outputId": "63b57959-6ce2-4d4f-f462-ae3002424292"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the number of metrics used in model compilation\n",
        "results = best_model.evaluate(testing_padded, labels_test)\n",
        "\n",
        "# Extracting specific metrics\n",
        "test_loss = results[0]\n",
        "test_accuracy = results[1]\n",
        "precision = results[2]\n",
        "recall = results[3]\n",
        "\n",
        "# Printing the results\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZEYTVoi2f4W",
        "outputId": "c01ea2dc-9d75-4c62-eef7-308024819857"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.8655 - loss: 0.3449 - precision: 0.8935 - recall: 0.8589\n",
            "Test Loss: 0.33880487084388733\n",
            "Test Accuracy: 0.8726483583450317\n",
            "Precision: 0.9048991203308105\n",
            "Recall: 0.8509485125541687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_bayesian_optimization = kt.BayesianOptimization(\n",
        "    build_model,  # model function\n",
        "    objective='val_accuracy',  # The metric to optimize\n",
        "    max_trials=20,  # Number of different models to try\n",
        "    executions_per_trial=1,  # Number of times to evaluate each model\n",
        "    directory='my_dir',  # Directory to save results\n",
        "    project_name='my_bayesian_optimization'  # Project name\n",
        ")\n",
        "\n",
        "tuner_bayesian_optimization.search(\n",
        "    padded,                # Training data\n",
        "    labels_train,          # Training labels\n",
        "    epochs=20,             # Number of epochs for each trial\n",
        "    validation_data=(testing_padded, labels_test),  # Validation data\n",
        "    callbacks=[early_stopping]  # Early stopping to prevent overfitting\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnHXZf7d2kTF",
        "outputId": "d4726712-41f9-4897-d2b5-23d797e08ac6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 04m 16s]\n",
            "val_accuracy: 0.8581765294075012\n",
            "\n",
            "Best val_accuracy So Far: 0.8740954995155334\n",
            "Total elapsed time: 02h 05m 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Best models after tuning\n",
        "best_model_random_search = tuner_random_search.get_best_models(num_models=1)[0]\n",
        "best_model_bayesian_optimization = tuner_bayesian_optimization.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Get predictions from both models\n",
        "preds_model_random_search = best_model_random_search.predict(testing_padded)\n",
        "preds_model_bayesian_optimization = best_model_bayesian_optimization.predict(testing_padded)\n",
        "\n",
        "# Define the weights for each model\n",
        "weight_random_search = 0.6  # Higher weight for the better-performing model\n",
        "weight_bayesian_optimization = 0.4  # Lower weight for the other model\n",
        "\n",
        "# Perform weighted averaging of predictions\n",
        "ensemble_preds = (weight_random_search * preds_model_random_search) + (weight_bayesian_optimization * preds_model_bayesian_optimization)\n",
        "\n",
        "# Threshold the probabilities to get final predictions\n",
        "final_preds = (ensemble_preds > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(labels_test, final_preds)\n",
        "precision = precision_score(labels_test, final_preds)\n",
        "recall = recall_score(labels_test, final_preds)\n",
        "\n",
        "print(f'Ensemble Model Accuracy: {accuracy}')\n",
        "print(f'Ensemble Model Precision: {precision}')\n",
        "print(f'Ensemble Model Recall: {recall}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjiXBLwsDFIr",
        "outputId": "cc531925-e532-4216-a3ed-12bf55d57efd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step\n",
            "Ensemble Model Accuracy: 0.8712011577424024\n",
            "Ensemble Model Precision: 0.8910614525139665\n",
            "Ensemble Model Recall: 0.8644986449864499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siYCodsBoQYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}